<?xml version="1.0" encoding="UTF-8"?>
<quiz xmlns="https://bigoquiz.com/document" format_version="1" id="string_algorithms">
    <title>String Algorithms</title>

    <section id="string-algorithms-substring-search">
        <title>Substring Search Algorithms</title>
        <link>https://en.wikipedia.org/wiki/String_searching_algorithm</link>
        <subsection id="string-algorithms-substring-search-description" answers_as_choices="true" and_reverse="true">
            <title>Description</title>

            <!--TODO: The Z algorithm is mentioned in chapter 1 of Dan Gusfield's
                "string-algorithms on Strings, Trees and Sequences: Computer Science and Computational Biology" book,
                and subsequently on several web site,
                but that doesn't seem to say who invented the algorithm.
            -->
            <question id="string-algorithms-substring-search-description-z-algorithm">
                <text>Z Algorithm</text>
                <link>http://www.geeksforgeeks.org/z-algorithm-linear-time-pattern-searching-algorithm/</link>
                <!-- TODO: Why isn't there a wikipedia page for the Z Algorithm. -->
                <answer>Concatenate the pattern, a special character, and the text. For each index, calculate the prefix length, if any, that starts at that position. After finding a prefix, subsequently reuse previously calculated values from the prefix itself.</answer>
                <!-- Tushar Roy's walkthrough, starting at linear-time Z Array construction: -->
                <video_url>https://youtu.be/CpZh4eF8QBw?t=5m45s</video_url>
                <code_url>https://github.com/murraycu/murrayc-algorithms-experiments/blob/master/src/substring_search/z_algorithm/main.cc</code_url>
                <!-- TODO: When is this useful, compared to KMP, BM, RK, etc? -->
            </question>

            <question id="string-algorithms-substring-search-description-kmp">
                <text>Knuth-Morris-Pratt (KMP)</text>
                <link>https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm</link>
                <answer>Pre-calculate a Deterministic Finite Automata (DFA), (also known as &quot;partial match table&quot; or &quot;failure function&quot;) that tells us, for each mismatch, where in the pattern we would need to start comparing characters again. For instance, this avoids re-comparing a prefix of the pattern that is identical to a suffix of the part of the pattern compared so far.</answer>
                <note>Or, to use less space than a DFA, create a prefix array, and step through it more than once each time.</note>
                <!-- Tushar Roy's video assumes use of a prefix array, though Sedgewick uses a DFA, both of which are valid. -->
                <video_url>https://www.youtube.com/watch?v=GTJr8OvyEVQ&amp;t=259s</video_url>
                <code_url>https://github.com/murraycu/murrayc-algorithms-experiments/blob/master/src/substring_search/kmp_with_prefix_array/main.cc</code_url>
                <!-- or with DFA: https://github.com/murraycu/murrayc-algorithms-experiments/blob/master/src/substring_search/kmp_with_dfa/main.cc -->
            </question>

            <question id="string-algorithms-substring-search-description-boyer-moore">
                <text>Boyer-Moore</text>
                <link>https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string_search_algorithm</link>
                <answer>Pre-calculate the right-most position of each character in the pattern. When there is a mismatch, skip ahead that much and compare again from the start of the pattern.</answer>
                <code_url>https://github.com/murraycu/murrayc-algorithms-experiments/blob/master/src/substring_search/boyer_moore/main.cc</code_url>
            </question>

            <question id="string-algorithms-substring-search-description-rabin-karp">
                <text>Rabin-Karp</text>
                <link>https://en.wikipedia.org/wiki/Rabin%E2%80%93Karp_algorithm</link>
                <answer>Compare hashes of the substrings, generating the next hash based on the previous hash.</answer>
                <video_url>https://www.youtube.com/watch?v=H4VrKHVG5qI</video_url>
                <code_url>https://github.com/murraycu/murrayc-algorithms-experiments/blob/master/src/substring_search/rabin_karp/main.cc</code_url>
            </question>

            <!-- TODO: Boyer-Moore-Horspool -->
            <!-- TODO: Aho-Corasick -->
        </subsection>

        <subsection id="string-algorithms-substring-search-preprocessing" answers_as_choices="true" and_reverse="true">
            <title>Preprocessing</title>

            <question id="string-algorithms-substring-search-preprocessing-z-algorithm">
                <text>Z Algorithm</text>
                <link>http://www.geeksforgeeks.org/z-algorithm-linear-time-pattern-searching-algorithm/</link>
                <!-- TODO: Why isn't there a wikipedia page for the Z Algorithm. -->
                <answer>Build an array of length pattern + $ + text. For each index, calculate the prefix length, if any, that starts at that position. After finding a prefix (a Z box), reuse previous Z values from the start. But if the previous Z value is as large as the remaining Z box, continue checking for the rest of a matching prefix after the Z box.</answer>
                <code_url>https://github.com/murraycu/murrayc-algorithms-experiments/tree/master/src/substring_search/z_algorithm</code_url>
            </question>

            <question id="string-algorithms-substring-search-preprocessing-kmp-with-dfa">
                <text>Knuth-Morris-Pratt (KMP) with a DFA</text>
                <link>https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm</link>
                <answer>Build a 2D array of pattern-size * alphabet-size. With x initially 0, set all dfa[pattern-pos][] to the values at dfa[x], then set dfa[pattern-pos][character-code] = pattern-pos + 1, update x to this value, and move to the next pattern position. </answer>
                <code_url>https://github.com/murraycu/murrayc-algorithms-experiments/blob/master/src/substring_search/kmp_with_dfa/main.cc</code_url>
            </question>

            <question id="string-algorithms-substring-search-preprocessing-kmp-with-prefix-array">
                <text>Knuth-Morris-Pratt (KMP) with a Prefix Array</text>
                <link>https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm</link>
                <answer>Build an array the same length as the pattern. With x initially 0 and i initially 1, if pattern[i] == pattern[x] then pa[i] = x + 1 and increment x and i, else x = pa[x-1] and try again. pa[pos] is then the number of characters at and before pos  (the suffix) that match the characters from position 0 (the prefix).</answer>
                <video_url>https://www.youtube.com/watch?v=KG44VoDtsAA</video_url>
                <code_url>https://github.com/murraycu/murrayc-algorithms-experiments/blob/master/src/substring_search/kmp_with_prefix_array/main.cc</code_url>
            </question>

            <question id="string-algorithms-substring-search-preprocessing-boyer-moore">
                <text>Boyer-Moore</text>
                <link>https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string_search_algorithm</link>
                <answer>Build an array of alphabet-size. Iterate over the pattern, from left to right, marking the (rightmost so far) position of the character in the array.</answer>
                <code_url>https://github.com/murraycu/murrayc-algorithms-experiments/blob/master/src/substring_search/boyer_moore/main.cc</code_url>
            </question>

            <question id="string-algorithms-substring-search-preprocessing-rabin-karp">
                <text>Rabin-Karp</text>
                <link>https://en.wikipedia.org/wiki/Rabin%E2%80%93Karp_algorithm</link>
                <answer>Generate a hash of the pattern.</answer>
                <code_url>https://github.com/murraycu/murrayc-algorithms-experiments/blob/master/src/substring_search/rabin_karp/main.cc</code_url>
            </question>
        </subsection>

        <subsection id="string-algorithms-substring-search-time-complexity" answers_as_choices="true" and_reverse="true">
            <title>Time Complexity</title>

            <!-- TODO: Z algorithm
            <question id="string-algorithms-substring-search-time-z-algorithm">
                <link>http://www.geeksforgeeks.org/z-algorithm-linear-time-pattern-searching-algorithm/</link>
                ODO: Why isn't there a wikipedia page for the Z Algorithm.
                <text>Z Algorithm</text>
                <answer></answer>
            </question>
            -->

            <!-- These are based on page 779 of Sedgewick's Algorithms book, 4th edition. -->
            <question id="string-algorithms-substring-search-time-kmp">
                <text>Knuth-Morris-Pratt (KMP)</text>
                <link>https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm</link>
                <answer>O(2N), typically 1.1N</answer>
            </question>

            <question id="string-algorithms-substring-search-time-boyer-moore">
                <text>Boyer-Moore</text>
                <link>https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string_search_algorithm</link>
                <answer>O(3N), typically N/M</answer>
            </question>

            <question id="string-algorithms-substring-search-time-rabin-karp">
                <text>Rabin-Karp</text>
                <link>https://en.wikipedia.org/wiki/Rabin%E2%80%93Karp_algorithm</link>
                <answer>O(7N), typically 7N</answer>
            </question>
        </subsection>

        <subsection id="string-algorithms-substring-search-extra-space" answers_as_choices="true" and_reverse="true">
            <title>Extra space</title>

            <question id="string-algorithms-substring-search-extra-space-z-algorithm">
                <text>Z Algorithm</text>
                <link>http://www.geeksforgeeks.org/z-algorithm-linear-time-pattern-searching-algorithm/</link>
                <!-- TODO: Why isn't there a wikipedia page for the Z Algorithm. -->
                <answer>O(M + N) (substring length + text length)</answer>
            </question>

            <!-- These are based on page 779 of Sedgewick's Algorithms book, 4th edition. -->
            <question id="string-algorithms-substring-search-extra-space-kmp">
                <text>Knuth-Morris-Pratt (KMP)</text>
                <link>https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm</link>
                <answer>O(MR) (substring length * alphabet size)</answer>
            </question>

            <question id="string-algorithms-substring-search-extra-space-boyer-moore">
                <text>Boyer-Moore</text>
                <link>https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string_search_algorithm</link>
                <answer>O(R) (alphabet size)</answer>
            </question>

            <question id="string-algorithms-substring-search-extra-space-rabin-karp">
                <text>Rabin-Karp</text>
                <link>https://en.wikipedia.org/wiki/Rabin%E2%80%93Karp_algorithm</link>
                <answer>O(1)</answer>
            </question>
        </subsection>

        <subsection id="string-algorithms-substring-search-backtracking" answers_as_choices="true">
            <title>Backup in input?</title>
            <question id="string-algorithms-substring-search-backtracking-z-algorithm">
                <text>Z Algorithm</text>
                <link>http://www.geeksforgeeks.org/z-algorithm-linear-time-pattern-searching-algorithm/</link>
                <!-- TODO: Why isn't there a wikipedia page for the Z Algorithm. -->
                <answer>No backup required</answer>
            </question>

            <question id="string-algorithms-substring-search-backtracking-kmp">
                <text>Knuth-Morris-Pratt (KMP)</text>
                <link>https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm</link>
                <answer>No backup required</answer>
            </question>

            <question id="string-algorithms-substring-search-backtracking-boyer-moore">
                <text>Boyer-Moore</text>
                <link>https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string_search_algorithm</link>
                <answer>Backup required</answer>
            </question>

            <question id="string-algorithms-substring-search-backtracking-rabin-karp">
                <text>Rabin-Karp</text>
                <link>https://en.wikipedia.org/wiki/Rabin%E2%80%93Karp_algorithm</link>
                <answer>No backup required</answer>
            </question>
        </subsection>
    </section>

    <section id="string-algorithms-similarity">
        <title>Similarity</title>
        <link>https://en.wikipedia.org/wiki/Category:String_similarity_measures</link>
        <subsection id="string-algorithms-similarity-description" answers_as_choices="true" and_reverse="true">
            <title>Description</title>

            <question id="string-algorithms-similarity-description-needleman-wunsch">
                <text>Needleman-Wunsch Sequence Algorithm</text>
                <link>https://en.wikipedia.org/wiki/Needleman%E2%80%93Wunsch_algorithm</link>
                <answer>Align two strings by inserting as few spaces as possible so that characters match.</answer>
            </question>

            <question id="string-algorithms-similarity-description-levenshtein-distance">
                <text>Levenshtein Distance</text>
                <link>https://en.wikipedia.org/wiki/Levenshtein_distance</link>
                <answer>Count the number of character edits (removal, insertion, or substitution) needed to make two strings identical.</answer>
            </question>
        </subsection>

        <subsection id="string-algorithms-similarity-implementation" answers_as_choices="true" and_reverse="true">
            <title>Implementation</title>

            <question id="string-algorithms-similarity-implementation-needleman-wunsch">
                <text>Needleman-Wunsch Sequence Algorithm</text>
                <link>https://en.wikipedia.org/wiki/Needleman%E2%80%93Wunsch_algorithm</link>
                <answer>Dynamic Programming. Subproblem is score for matching i characters in a with j characters in b, which is the minimum cost of matching one less character from either a or b, or from both, matching, inserting, or deleting a character.</answer>
            </question>

            <question id="string-algorithms-similarity-implementation-levenshtein-distance">
                <text>Levenshtein Distance</text>
                <link>https://en.wikipedia.org/wiki/Levenshtein_distance</link>
                <answer>Dynamic Programming. Subproblem is score for aligning i characters in a with j characters in b, which is the minimum cost of using one less character from either a or b, or from both, adding a space or mismatch if necessary.</answer>
            </question>
        </subsection>
    </section>

    <section id="string-algorithms-misc">
        <title>Miscellaneous</title>

        <question id="string-algorithms-misc-manachers-algorithm">
            <text>Manacher's Algorithm</text>
            <link>https://en.wikipedia.org/wiki/Longest_palindromic_substring#Manacher.27s_algorithm</link>
            <video_url>https://www.youtube.com/watch?v=V-sEwsca1ak</video_url>
            <answer>Longest Palindromic Substring</answer>
            <note>This is linear O(n).</note>
            <!--
            Implementation (for odd-lengths): From beginning to end, expand from the position, discovering the
            size of the palindrome centered there. The right side is the mirror of the left side, so we already know
            minimum values for some of the following positions, as long as that value, and its previous palindrome, do not go beyond the current palindrome's limits.
            Start checking again from the following position with the largest such known minimum palindrome.
            For even-length palindromes, either consider the center to be between characters, or insert a $ between characters and reuse the same algorithm, dividing the answer by 2.
            -->
        </question>
        <!-- TODO: Longest Palindromic Subsequence -->
    </section>


    <!-- Strings and sets:
      Set Cover:
      Set Packing:
      String Matching:
      Approximate string matching:
        DP with costs for substitution, insertion, and deletion.
          Longest Common subsequence (LCS) is string distance DP algorithm without substitution.
          Longest increasing subsequence?
        Bit-parallel algorithm (page 633 of TADM).
      Longest Common Subsequence:
        Difference to Longest Common Substring
        With Suffix Tree: Insert both strings into the same suffix tree. Find the deepest node that is for both strings. O(n + m).
        The DP algorithm is O(nm).
      Longest Repeated Substring:
        With Suffix Tree: Put the string in a suffix tree. Find the deepest internal node.
      Shortest Common Substring

      Find lexicographic location of Tk in T1 to Tn: Put them all in a trie, with terminating $ on each string.

      Multiple ($-terminated) strings in a trie, with ordered edges.
        Lexicographic order: in-order traversal gives us lexicographic order.
        Lexicographic predecessor: Find node that matches as much as possible. Predecessor is max in left sub-tree.
          (Maintain sub-tree min/max to make this faster.)
        Lexicographic successor: Find node that matches as much as possible. Successor is min in right sub-tree.
          (Maintain sub-tree min/max to make this faster.)
        LCA, LCP.

      ( https://www.youtube.com/watch?v=NinWEPPrkDQ )
      Tray: (Used for Trie/Suffix-Tree nodes to give O(P + lg(sigma)) lookup with O(T) space.

      ( https://youtu.be/NinWEPPrkDQ?t=3683 )
      "document retrieval" data structure: To find the matching documents without finding all the individual matches,
      in O(P + #-of-documents-matching).
        Uses RMQ.





      String matching without pre-processing (for instance, without suffix tree):
      (Without string processing it's generally O(T) time (T=length of searched text),
       but with preprocessing it can be O(P) time (P=length of pattern), often in O(T) space.)
      Knuth-Morris-Pratt Algorithm
        https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm
        "using precomputation to examine each text character only once"
      Boyer-Moore Algorithm
        https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string_search_algorithm
        "Skips forward as many as possible for the search to succeed,"
      Rabin-Karp Algorithm
        https://en.wikipedia.org/wiki/Rabin%E2%80%93Karp_algorithm
        Uses a rolling hash.
        Uses: Detect plagiarism. Multiple pattern search.
          Wikipedia says "Inferior for single pattern searching to Knuth–Morris–Pratt algorithm, Boyer–Moore string search algorithm"
      Aho-Corasick Algorithm
        https://en.wikipedia.org/wiki/Aho%E2%80%93Corasick_algorithm
        "constructs a finite state machine that resembles a trie with additional links between the various internal nodes"

      https://www.youtube.com/watch?v=0rCFkuQS968
      Range Minimum Query (RMQ): Discover index of minimum value in a range of values:
        Put the values in a cartesian tree by splitting at the smallest values, recursively. Then the LCA of any two nodes is the RMQ.
        (You would need to keep an array associating each index with a tree node.)
        Can construct cartesian tree in (amortized) O(n) time by adding each node and, if necessary, walking up and splitting, making children into left nodes.
        The RMQ of indices in the the array also tells you the LCA of nodes in the tree.
        Use Euler Tour (in order traversal) to get RMQ array whose values only differ by 1.

      Level Ancestor (LA): Find kth parent of node in less than O(n) time.
       Long-path decomposition:

       Ladder decomposition:

      Lowest Common Ancestor (LCA): https://en.wikipedia.org/wiki/Lowest_common_ancestor
    -->

    <!-- Postfix notation evaluation: Push operands on to stack. When we see an operator, we pop 2 items, apply, and push back.
         (We don't need to care about operator precedence. -->
    <!-- Proofs:
    Job/Interval Scheduling: Exchange argument: Order edge in order of duration / finish time.
    Kruskal's MST: Exchange Argument: Order edges in order of increasing cost. TODO-->

    <!-- Ukkonen's algorithm for Suffix Tree Construction:
         https://en.wikipedia.org/wiki/Ukkonen%27s_algorithm
         an "online algorithm" -->

    <!-- Online algorithms (Processes input piece by piece without having the whole input from the start.)
    https://en.wikipedia.org/wiki/Online_algorithm
      Insertion Sort
      Ukkonen's algorithm for Suffix Tree Construction
      Farach's algorithm for Suffix Tree Construction
      Insertion Sort
      Boyer-Moore?

    Offline algorithms: Need whole data from the start:
      Selection Sort
      McCreights's algorithm for Suffix Tree Construction

    -->





    <!-- encoding:
    huffman encoding
    arithmetic encoding (uses Fenwick Tree): https://en.wikipedia.org/wiki/Arithmetic_coding

    Gray codes: Successive values differ by only one bit.
    -->


</quiz>