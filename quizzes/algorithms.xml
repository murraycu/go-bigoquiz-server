<?xml version="1.0" encoding="UTF-8"?>
<quiz xmlns="https://bigoquiz.com/document" format_version="1" id="algorithms">
    <title>Algorithms</title>
    <section id="algorithms-sort">
        <title>Sorting Algorithms</title>
            <subsection id="algorithms-sort-description" answers_as_choices="true" and_reverse="true">
                <title>Description</title>

                <question id="algorithms-sort-description-quicksort">
                    <text>Quicksort</text>
                    <link>https://en.wikipedia.org/wiki/Quicksort</link>
                    <answer>Find partition and recurse.</answer>
                </question>
                <question id="algorithms-sort-description-3-way-quicksort">
                    <text>3-Way Quicksort</text>
                    <link>https://en.wikipedia.org/wiki/Quicksort#Repeated_elementst</link>
                    <answer>Find partition and recurse, partitioning into less, equal, and greater than the pivot.</answer>
                </question>
                <question id="algorithms-sort-description-mergesort">
                    <text>Mergesort</text>
                    <link>https://en.wikipedia.org/wiki/Merge_sort</link>
                    <answer>Divide, sort (recurse), merge.</answer>
                </question>
                <question id="algorithms-sort-description-heapsort">
                    <text>Heapsort</text>
                    <link>https://en.wikipedia.org/wiki/Heapsort</link>
                    <answer>Like Selection Sort, but first heapifies the array and then chooses the largest values.</answer>
                </question>
                <question id="algorithms-sort-description-timsort">
                    <text>Timsort</text>
                    <link>https://en.wikipedia.org/wiki/Timsort</link>
                    <answer>Hybrid of Mergesort and Insertion Sort. Finds ordered subsequences.</answer>
                </question>
                <question id="algorithms-sort-description-insertion-sort">
                    <text>Insertion Sort</text>
                    <link>https://en.wikipedia.org/wiki/Insertion_sort</link>
                    <answer>Move each item, by neighbour swaps, to its location in the sorted list. Like sorting a hand of cards.</answer>
                </question>
                <question id="algorithms-sort-description-selection-sort">
                    <text>Selection Sort</text>
                    <link>https://en.wikipedia.org/wiki/Selection_sort</link>
                    <answer>Repeatedly finds smallest item and moves it to the end of the sorted section at the start.</answer>
                </question>
                <question id="algorithms-sort-description-shell-sort">
                    <text>Shellsort</text>
                    <link>https://en.wikipedia.org/wiki/Shellsort</link>
                    <answer>Like Insertion Sort, but considering every hth element, then again for lower h, until h is 1.</answer>
                </question>
                <question id="algorithms-sort-description-counting-sort">
                    <text>Counting Sort</text>
                    <answer>Count how often each value appears. Calculate the start index for each value. Copy each value to the start index in the output, decrementing the start index each time for each value.</answer>
                </question>
                <question id="algorithms-sort-description-radix-sort">
                    <text>Radix Sort (LSD or MSD string sort)</text>
                    <link>https://en.wikipedia.org/wiki/Radix_sort</link>
                    <answer>Sort d times, each time examining just b bits, using counting sort or bucket sort.</answer>
                </question>
                <question id="algorithms-sort-description-bucket-sort">
                    <text>Bucket Sort</text>
                    <answer>Scatter items into buckets for ranges. Sort each bucket. Fill the array from the sorted buckets.</answer>
                </question>
                <question id="algorithms-sort-description-bubble-sort">
                    <text>Bubble Sort</text>
                    <answer>Compare and swap pairs until no more swaps are necessary.</answer>
                </question>

                <!-- TODO? Burstsort (uses a Trie) https://en.wikipedia.org/wiki/Burstsort -->
            </subsection>

            <!-- This is a duplication of the more complete information in bigo.xml,
            but it seems useful to have it here too. -->
            <subsection id="algorithms-sort-time" answers_as_choices="true" and_reverse="true">
                <title>Average Time</title>

                <question id="algorithms-sort-time-quicksort">
                    <text>Quicksort</text>
                    <link>https://en.wikipedia.org/wiki/Quicksort</link>
                    <answer>O(n log(n))</answer>
                </question>
                <question id="algorithms-sort-time-3-way-quicksort">
                    <text>Quicksort</text>
                    <link>https://en.wikipedia.org/wiki/Quicksort#Repeated_elements</link>
                    <answer>O(n log(n))</answer>
                    <note>But worst time is O(n^2). O(n log(n)) time requires randomization.</note>
                </question>
                <question id="algorithms-sort-time-mergesort">
                    <text>Mergesort</text>
                    <link>https://en.wikipedia.org/wiki/Merge_sort</link>
                    <answer>O(n log(n))</answer>
                    <note>The worst time is also O(n log(n)).</note>
                </question>
                <question id="algorithms-sort-time-heapsort">
                    <text>Heapsort</text>
                    <link>https://en.wikipedia.org/wiki/Heapsort</link>
                    <answer>O(n log(n))</answer>
                </question>
                <question id="algorithms-sort-time-timsort">
                    <text>Timsort</text>
                    <link>https://en.wikipedia.org/wiki/Timsort</link>
                    <answer>O(n log(n))</answer>
                </question>
                <question id="algorithms-sort-time-insertion-sort">
                    <text>Insertion Sort</text>
                    <link>https://en.wikipedia.org/wiki/Insertion_sort</link>
                    <answer>O(n ^ 2)</answer>
                </question>
                <question id="algorithms-sort-time-selection-sort">
                    <text>Selection Sort</text>
                    <link>https://en.wikipedia.org/wiki/Selection_sort</link>
                    <answer>O(n ^ 2)</answer>
                </question>
                <question id="algorithms-sort-time-shell-sort">
                    <text>Shellsort</text>
                    <link>https://en.wikipedia.org/wiki/Shellsort</link>
                    <answer>O(n log(n)^2)</answer>
                </question>
                <question id="algorithms-sort-time-counting-sort">
                    <text>Counting Sort</text>
                    <answer>O(n + k)</answer>
                    <note>This is the time to examine n items and then the time to examine each value in the range k.</note>
                </question>
                <question id="algorithms-sort-time-radix-sort">
                    <text>Radix Sort (LSD or MSD string sort)</text>
                    <link>https://en.wikipedia.org/wiki/Radix_sort</link>
                    <answer>O(nk)</answer>
                    <note>This is the time to do d (k) counting sorts (each O(n + b), where b is the range, for instance, of a single digit), where d is the number of digits. This is only really O(nc) if the range k is a polynomial of k, so k &lt;= n^c.</note>
                    <video_url>https://youtu.be/Nz1KZXbghj8?t=44m41s</video_url>
                </question>
                <question id="algorithms-sort-time-bucket-sort">
                    <text>Bucket Sort</text>
                    <answer>O(n + k)</answer>
                    <note>This is the time to put n keys in n buckets of size k and then to go through each bucket putting the items back. This only works if the values are evenly distributed in the range.</note>
                </question>
                <question id="algorithms-sort-time-bubble-sort">
                    <text>Bubble Sort</text>
                    <answer>O(n ^ 2)</answer>
                </question>

                <!-- TODO? Burstsort (uses a Trie) https://en.wikipedia.org/wiki/Burstsort -->
            </subsection>


        <subsection id="algorithms-sort-advantages" answers_as_choices="true">
            <title>Advantages</title>

            <question id="algorithms-sort-advantages-quicksort">
                <text>Quicksort</text>
                <link>https://en.wikipedia.org/wiki/Quicksort</link>
                <answer>In-place (O(log(n)) space). Data Locality. Small coefficient of O(n log(n)).</answer>
            </question>
            <question id="algorithms-sort-advantages-3-way-quicksort">
                <text>3-Way Quicksort</text>
                <link>https://en.wikipedia.org/wiki/Quicksort#Repeated_elements</link>
                <answer>In-place (O(log(n)) space). Data Locality. Small coefficient of O(n log(n)). Linear on equal values.</answer>
            </question>
            <question id="algorithms-sort-advantages-mergesort">
                <text>Mergesort</text>
                <link>https://en.wikipedia.org/wiki/Merge_sort</link>
                <answer>O(n log(n)) worst case time. Stable. Data Locality. Parallelizable. Can be External.</answer>
            </question>
            <question id="algorithms-sort-advantages-heapsort">
                <text>Heapsort</text>
                <link>https://en.wikipedia.org/wiki/Heapsort</link>
                <answer>O(n log(n)) worst case time. O(1) space.</answer>
            </question>
            <question id="algorithms-sort-advantages-timsort">
                <text>Timsort</text>
                <link>https://en.wikipedia.org/wiki/Timsort</link>
                <answer>O(n) best case time.</answer>
            </question>
            <question id="algorithms-sort-advantages-insertion-sort">
                <text>Insertion Sort</text>
                <answer>Fast for small n, even though it has O(n^2) average time. Fast for nearly-sorted items. Online algorithm.</answer>
                <!-- See other online sorts: https://en.wikipedia.org/wiki/Category:Online_sorts -->
            </question>
            <question id="algorithms-sort-advantages-selection-sort">
                <text>Selection Sort</text>
                <answer>Minimal swaps.</answer>
            </question>
            <!-- None?
            <question id="algorithms-sort-advantages-shell-sort">
                <text>Shell Sort</text>
                <answer></answer>
            </question>
            -->
            <question id="algorithms-sort-advantages-counting-sort">
                <text>Counting Sort</text>
                <link>https://en.wikipedia.org/wiki/Counting_sort</link>
                <answer>O(n) time, but with O(m) space</answer>
                <note>Therefore, this is unsuitable when the range m is much greater than n.</note>
            </question>
            <question id="algorithms-sort-advantages-radix-sort">
                <text>Radix Sort (LSD or MSD string sort)</text>
                <link>https://en.wikipedia.org/wiki/Radix_sort</link>
                <answer>O(n) time. Minimal space.</answer>
            </question>
            <question id="algorithms-sort-advantages-bucket-sort">
                <text>Bucket Sort</text>
                <link>https://en.wikipedia.org/wiki/Bucket_sort</link>
                <answer>Like Counting Sort, but uses O(n) space instead of O(m) space.</answer>
            </question>
            <!-- None?
            <question id="algorithms-sort-advantages-bubble-sort">
                <text>Bubble Sort</text>
                <answer></answer>
            </question>
            -->
        </subsection>

        <!-- TODO: What do they need space for? -->

        <subsection id="algorithms-sort-stability" answers_as_choices="true">
            <title>Sort Stability</title>
            <link>https://en.wikipedia.org/wiki/Stable_sort</link>

            <question id="algorithms-sort-stability-quicksort">
                <text>Quicksort</text>
                <link>https://en.wikipedia.org/wiki/Quicksort</link>
                <answer>Unstable</answer>
            </question>
            <question id="algorithms-sort-stability-3-way-quicksort">
                <text>3-Way Quicksort</text>
                <link>https://en.wikipedia.org/wiki/Quicksort#Repeated_elements</link>
                <answer>Unstable</answer>
            </question>
            <question id="algorithms-sort-stability-mergesort">
                <text>Mergesort</text>
                <link>https://en.wikipedia.org/wiki/Merge_sort</link>
                <answer>Stable</answer>
            </question>
            <question id="algorithms-sort-stability-heapsort">
                <text>Heapsort</text>
                <link>https://en.wikipedia.org/wiki/Heapsort</link>
                <answer>Unstable</answer>
            </question>
            <question id="algorithms-sort-stability-timsort">
                <text>Timsort</text>
                <link>https://en.wikipedia.org/wiki/Timsort</link>
                <answer>Stable</answer>
            </question>
            <question id="algorithms-sort-stability-insertion-sort">
                <text>Insertion Sort</text>
                <link>https://en.wikipedia.org/wiki/Insertion_sort</link>
                <answer>Stable</answer>
            </question>
            <question id="algorithms-sort-stability-selection-sort">
                <text>Selection Sort</text>
                <link>https://en.wikipedia.org/wiki/Selection_sort</link>
                <answer>Unstable</answer>
            </question>
            <question id="algorithms-sort-stability-shellsort">
                <text>Shellsort</text>
                <link>https://en.wikipedia.org/wiki/Shellsort</link>
                <answer>Unstable</answer>
            </question>
            <question id="algorithms-sort-stability-counting-sort">
                <text>Counting Sort</text>
                <answer>Stable</answer>
            </question>
            <question id="algorithms-sort-stability-radix-sort">
                <text>Radix Sort (LSD or MSD string sort)</text>
                <link>https://en.wikipedia.org/wiki/Radix_sort</link>
                <answer>Stable</answer>
            </question>
            <question id="algorithms-sort-stability-bucket-sort">
                <text>Bucket Sort</text>
                <answer>Stable</answer>
            </question>
            <question id="algorithms-sort-stability-bubble-sort">
                <text>Bubble Sort</text>
                <answer>Stable</answer>
            </question>
        </subsection>

        <subsection id="algorithms-sort-inplace" answers_as_choices="true">
            <title>In Place or Not</title>
            <link>https://en.wikipedia.org/wiki/In-place_algorithm</link>

            <question id="algorithms-sort-inplace-quicksort">
                <text>Quicksort</text>
                <link>https://en.wikipedia.org/wiki/Quicksort</link>
                <answer>In-place (but small additional space needed)</answer>
                <note>The call stack requires O(log(n)) space.</note>
            </question>
            <question id="algorithms-sort-inplace-3-way-quicksort">
                <text>3-Way Quicksort</text>
                <link>https://en.wikipedia.org/wiki/Quicksort#Repeated_elements</link>
                <answer>In-place (but small additional space needed)</answer>
                <note>The call stack requires O(log(n)) space.</note>
            </question>
            <question id="algorithms-sort-inplace-mergesort">
                <text>Mergesort</text>
                <link>https://en.wikipedia.org/wiki/Merge_sort</link>
                <answer>Not in-place</answer>
            </question>
            <question id="algorithms-sort-inplace-heapsort">
                <text>Heapsort</text>
                <link>https://en.wikipedia.org/wiki/Heapsort</link>
                <answer>In-place</answer>
            </question>
            <question id="algorithms-sort-inplace-timsort">
                <text>Timsort</text>
                <link>https://en.wikipedia.org/wiki/Timsort</link>
                <answer>Not in-place</answer>
            </question>
            <question id="algorithms-sort-inplace-insertion-sort">
                <text>Insertion Sort</text>
                <link>https://en.wikipedia.org/wiki/Insertion_sort</link>
                <answer>In-place</answer>
            </question>
            <question id="algorithms-sort-inplace-selection-sort">
                <text>Selection Sort</text>
                <link>https://en.wikipedia.org/wiki/Selection_sort</link>
                <answer>In-place</answer>
            </question>
            <question id="algorithms-sort-inplace-shellsort">
                <text>Shellsort</text>
                <link>https://en.wikipedia.org/wiki/Shellsort</link>
                <answer>In-place</answer>
            </question>
            <question id="algorithms-sort-inplace-counting-sort">
                <text>Counting Sort</text>
                <answer>Not in-place</answer>
            </question>
            <question id="algorithms-sort-inplace-radix-sort">
                <text>Radix Sort (LSD or MSD string sort)</text>
                <link>https://en.wikipedia.org/wiki/Radix_sort</link>
                <answer>Not in-place</answer>
            </question>
            <question id="algorithms-sort-inplace-bucket-sort">
                <text>Bucket Sort</text>
                <answer>Not in-place</answer>
            </question>
            <question id="algorithms-sort-inplace-bubble-sort">
                <text>Bubble Sort</text>
                <answer>In-place</answer>
            </question>
        </subsection>

        <subsection id="algorithms-sort-comparison" answers_as_choices="true">
            <title>Comparison or Non-Comparison</title>
            <link>https://en.wikipedia.org/wiki/Comparison_sort</link>

            <question id="algorithms-sort-comparison-quicksort">
                <text>Quicksort</text>
                <link>https://en.wikipedia.org/wiki/Quicksort</link>
                <answer>Comparison</answer>
            </question>
            <question id="algorithms-sort-comparison-3-way-quicksort">
                <text>3-Way Quicksort</text>
                <link>https://en.wikipedia.org/wiki/Quicksort#Repeated_elementst</link>
                <answer>Comparison</answer>
            </question>
            <question id="algorithms-sort-comparison-mergesort">
                <text>Mergesort</text>
                <link>https://en.wikipedia.org/wiki/Merge_sort</link>
                <answer>Comparison</answer>
            </question>
            <question id="algorithms-sort-comparison-heapsort">
                <text>Heapsort</text>
                <link>https://en.wikipedia.org/wiki/Heapsort</link>
                <answer>Comparison</answer>
            </question>
            <question id="algorithms-sort-comparison-timsort">
                <text>Timsort</text>
                <link>https://en.wikipedia.org/wiki/Timsort</link>
                <answer>Comparison</answer>
            </question>
            <question id="algorithms-sort-comparison-insertion-sort">
                <text>Insertion Sort</text>
                <link>https://en.wikipedia.org/wiki/Insertion_sort</link>
                <answer>Comparison</answer>
            </question>
            <question id="algorithms-sort-comparison-selection-sort">
                <text>Selection Sort</text>
                <link>https://en.wikipedia.org/wiki/Selection_sort</link>
                <answer>Comparison</answer>
            </question>
            <question id="algorithms-sort-comparison-shellsort">
                <text>Shellsort</text>
                <link>https://en.wikipedia.org/wiki/Shellsort</link>
                <answer>Comparison</answer>
            </question>
            <question id="algorithms-sort-comparison-counting-sort">
                <text>Counting Sort</text>
                <answer>Non-Comparison</answer>
            </question>
            <question id="algorithms-sort-comparison-radix-sort">
                <text>Radix Sort (LSD or MSD string sort)</text>
                <link>https://en.wikipedia.org/wiki/Radix_sort</link>
                <answer>Non-Comparison</answer>
            </question>
            <question id="algorithms-sort-comparison-bucket-sort">
                <text>Bucket Sort</text>
                <answer>Non-Comparison</answer>
                <note>Although we don't compare keys with each other, we still need to compare the keys with a part of the range to put it in a bucket.</note>
            </question>
            <question id="algorithms-sort-comparison-bubble-sort">
                <text>Bubble Sort</text>
                <answer>Comparison</answer>
            </question>
        </subsection>
    </section>

    <!-- TODO: Link to the similar section in the graphs quiz? -->
    <section id="polynomial-or-np-complete" answers_as_choices="true">
        <title>Polynomial or NP-complete</title>
        <question id="polynomial-or-np-complete-2-sat">
            <text>2-satisfiability (2-SAT)</text>
            <link>https://en.wikipedia.org/wiki/2-satisfiability#Resolution_and_transitive_closure</link>
            <answer>Polynomial</answer>
        </question>

        <question id="polynomial-or-np-complete-boolean-satisfiability">
            <text>Boolean satisfiability</text>
            <link>https://en.wikipedia.org/wiki/Boolean_satisfiability_problem</link>
            <answer>NP-Complete</answer>
        </question>

        <question id="polynomial-or-np-complete-subset-sum">
            <text>Subset Sum</text>
            <link>https://en.wikipedia.org/wiki/Subset_sum_problem</link>
            <answer>NP-Complete</answer>
        </question>

        <question id="polynomial-or-np-complete-bin-packing">
            <text>Bin Packing</text>
            <link>https://en.wikipedia.org/wiki/Bin_packing_problem</link>
            <answer>NP-Complete</answer>
        </question>

        <question id="polynomial-or-np-complete-knapsack-problem">
            <text>(O-1) Knapsack Problem</text>
            <link>https://en.wikipedia.org/wiki/Knapsack_problem</link>
            <answer>NP-Complete</answer>
            <note>This is solvable by dynamic programming. The Fractional Knapsack problem is Polynomial, and solvable via a greedy algorithm.</note>
        </question>

        <question id="polynomial-or-np-complete-knapsack-problem">
            <text>Fractional Knapsack Problem</text>
            <link>https://en.wikipedia.org/wiki/Continuous_knapsack_problem</link>
            <answer>Polynomial</answer>
            <note>This is solvable by a greedy algorithm. The normal Knapsack problem is NP-Complete, and solvable via dynamic programming.</note>
        </question>

        <!-- TODO: Mention that this is hard, though we don't know if it's really NP-complete.
        <question id="polynomial-or-np-complete-factoring">
            <text>Integer Factorization</text>
            <link>https://en.wikipedia.org/wiki/Integer_factorization#Difficulty_and_complexity</link>
            <answer>NP-Complete</answer>
        </question>
        -->

        <question id="polynomial-or-np-complete-sorting">
            <text>Sorting</text>
            <link>https://en.wikipedia.org/wiki/Sorting_algorithm</link>
            <answer>Polynomial</answer>
        </question>
    </section>

    <!-- Types of algorithms: https://www.cs.princeton.edu/~wayne/kleinberg-tardos/ -->
    <section id="algorithms-types" answers_as_choices="true">
        <title>Types of Algorithms</title>

        <question id="type-dijkstra">
            <text>Dijkstra's shortest path algorithm</text>
            <link>https://en.wikipedia.org/wiki/Dijkstra's_algorithm</link>
            <answer>Greedy</answer>
        </question>

        <question id="type-huffman-codes">
            <!-- TODO: Actual name? -->
            <text>Algorithm for building Huffman Codes</text>
            <link>https://en.wikipedia.org/wiki/Huffman_coding#Basic_technique</link>
            <answer>Greedy</answer>
            <note>Bottom-up. Merge items (or combined items) with least frequency, at each step, giving the subtree the sum of their frequencies. Repeat.</note>
        </question>
        <!--
          Wrong answer: merge highest frequencies.
          Wrong answer: Always merge with the sub-tree so far. Instead merge subtrees only when they are the 2 smallest items.
          -->

        <question id="type-make-change-canonical">
            <text>Make change (with canonical coins)</text>
            <link>https://en.wikipedia.org/wiki/Change-making_problem#Greedy_method</link>
            <answer>Greedy</answer>
        </question>

        <question id="type-prims">
            <text>Prim's Algorithm for Minimum Spanning Tree</text>
            <link>https://en.wikipedia.org/wiki/Prim's_algorithm</link>
            <answer>Greedy</answer>
        </question>

        <question id="type-kruskals">
            <text>Kruskal's Algorithm for Minimum Spanning Tree</text>
            <link>https://en.wikipedia.org/wiki/Kruskal's_algorithm</link>
            <answer>Greedy</answer>
        </question>

        <!-- TODO: Greedy Algorithms: Scheduling (interval scheduling, minimizing lateness),
        Scheduling jobs: Length and weight. Completion Time.  Minimise W*C. So sort by
        Scheduling to avoid conflicts: Choose earliest finish time first.
        -->

        <question id="type-binary-search">
            <text>Binary Search</text>
            <link>https://en.wikipedia.org/wiki/Binary_search_algorithm</link>
            <answer>Divide and Conquer</answer>
        </question>

        <question id="type-quicksort">
            <text>Quicksort</text>
            <link>https://en.wikipedia.org/wiki/Quicksort</link>
            <answer>Divide and Conquer</answer>
        </question>

        <question id="type-mergesort">
            <text>Mergesort</text>
            <link>https://en.wikipedia.org/wiki/Merge_sort</link>
            <answer>Divide and Conquer</answer>
        </question>

        <question id="type-quickselect">
            <text>QuickSelect</text>
            <link>https://en.wikipedia.org/wiki/Quickselect</link>
            <answer>Divide and Conquer</answer>
        </question>

        <question id="type-strassen">
            <text>Strassen Matrix Multiplication</text>
            <link>https://en.wikipedia.org/wiki/Strassen_algorithm</link>
            <answer>Divide and Conquer</answer>
        </question>

        <question id="type-median-of-medians">
            <text>Median of Medians</text>
            <link>https://en.wikipedia.org/wiki/Strassen_algorithm</link>
            <answer>Divide and Conquer</answer>
            <video_url>https://youtu.be/EzeYI7p9MjU?t=55m26s</video_url>
        </question>

        <!-- TODO: but there are others.
        <question id="type-convex-hull">
            <text>Convex Hull</text>
            <link>https://en.wikipedia.org/wiki/Convex_hull_algorithms</link>
            <answer>Divide and Conquer</answer>
            <video_url>https://youtu.be/EzeYI7p9MjU?t=6m57s</video_url>
        </question>
        -->

        <!-- TODO: Divide and Conquer Algorithms:
        Hashing?,
        polynomial multiplication -->

        <question id="type-bellmann-ford">
            <text>Bellmann-Ford Single-Source Shortest Path</text>
            <link>https://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm</link>
            <answer>Dynamic Programming</answer>
            <note>Bellmann invented the term "Dynamic Programming".</note>
        </question>
        <!-- TODO: Uses: Internet Routing: Doesn't need to know the whole graph - Information about local paths can be sent to other servers. -->

        <question id="type-floyd-warshall">
            <text>Floyd Warshall Algorithm</text>
            <link>https://en.wikipedia.org/wiki/Floyd%E2%80%93Warshall_algorithm</link>
            <answer>Dynamic Programming</answer>
        </question>

        <question id="type-make-change-non-canonical">
            <text>Make change (with non-canonical coins)</text>
            <answer>Dynamic Programming</answer>
        </question>

        <question id="type-build-optimal-bst">
            <!-- TODO: Actual name? -->
            <text>Build an optimal binary search tree</text>
            <link>https://en.wikipedia.org/wiki/Optimal_binary_search_tree#Knuth.27s_dynamic_programming_algorithm</link>
            <answer>Dynamic Programming</answer>
            <note>Huffmann codes, which seem similar, can be built with a greedy algorithm.</note>
        </question>

        <question id="type-boyer-moore-voting-algorithm">
            <text>Boyer-Moore Voting Algorithm (Find majority element)</text>
            <link>https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_majority_vote_algorithm</link>
            <answer>Greedy</answer>
            <!-- TODO: This seems like a greedy algorithm, making local choices to achieve a global optimum, but it is not widely mentioned as a greedy algorithm. -->
        </question>

        <question id="type-activity-selection-problem">
            <text>Activity Selection Problem (Maximum number of activities with start and end times)</text>
            <link>https://en.wikipedia.org/wiki/Activity_selection_problem</link>
            <answer>Greedy</answer>
        </question>

        <question id="type-fft-cooley-tukey">
            <text>Fast Fourier Transform (FFT) (Cooley-Tukey Algorithm)</text>
            <link>https://en.wikipedia.org/wiki/Fast_Fourier_transform#Algorithms</link>
            <answer>Divide and Conquer</answer>
            <video_url>https://www.youtube.com/watch?v=iTMn0Kt18tg</video_url>
        </question>

        <question id="type-closest-pair-of-points">
            <text>Closest Pair of Points in a Plane</text>
            <link>https://en.wikipedia.org/wiki/Closest_pair_of_points_problem#Planar_case</link>
            <answer>Divide and Conquer</answer>
            <video_url>https://www.youtube.com/watch?v=xi-WF07rAQw</video_url>
        </question>

        <!--
        DP Algorithm chooses roots of left and right subtrees of subproblems. O(n^3) or O(n^2) if we check only between the left and right roots:
        https://stackoverflow.com/questions/16987670/dynamic-programming-why-knuths-improvement-to-optimal-binary-search-tree-on2
        -->

        <!-- TODO: Dynamic Programming Algorithms:
          Interval/Job Scheduling with weights:
            opt(R) = max 1 <= i <= n (wi + opt(Rfinish(i)))
            O(n^2) but apparently O(nlog(n)) is possible.
            Add the requirement that not all jobs can be done on the same machine (or by same person), then it is NP-complete.
          String Comparison.
          Independent Set of a Path Graph (in Stanford/Coursera course, part 2): https://www.coursera.org/learn/algorithm-design-analysis-2/lecture/TZgJM/wis-in-path-graphs-a-reconstruction-algorithm
            1 Dimension. (O(n)):
              A[i] = max(A[i-1], A[i-2] + w)
          Independent Set of a Tree Graph (in Stanford/Coursera course, part 2, quiz 3)
            "Recall our dynamic programming algorithm for computing the maximum-weight independent set of a path graph. Consider the following proposed extension to more general graphs. Consider an undirected graph with positive vertex weights. For a vertex v, obtain the graph G′(v) by deleting v and its incident edges from G, and obtain the graph G″(v) from G by deleting v, its neighbors, and all of the corresponding incident edges from G. Let OPT(H) denote the value of a maximum-weight independent set of a graph H. Consider the formula OPT(G)=max{OPT(G′(v)),wv+OPT(G″(v))}, where v is an arbitrary vertex of G of weight wv"
          Sequence Alignment for Needleman-Wunsch score: https://www.coursera.org/learn/algorithm-design-analysis-2/lecture/QJkyp/optimal-substructure
            Score, with cost for gaps in either string. 3 cases: No gap, gap in X, or gap in Y. 2 Dimensions.
              A[i, j] = min(A[i-1, j-1], A[i-1, j] + gap_cost, A[i, j-1] + gap_cost)
         -->
    </section>

    <section id="algorithms-on-arrays" answers_as_choices="true">
        <title>Algorithms on Arrays</title>
        <question id="algorithms-on-arrays-max-subarray-with-empty">
            <text>Maximum Subarray (allowing an empty subarray)</text>
            <link>https://en.wikipedia.org/wiki/Maximum_subarray_problem</link>
            <answer>Calculate the sum so far, not allowing the sum to be less than 0. Maintain the maximum. (Kadane's Algorithm)</answer>
        </question>

        <question id="algorithms-on-arrays-max-subarray-without-empty">
            <text>Maximum Subarray (not allowing an empty subarray)</text>
            <answer>Calculate the sum so far, not allowing the sum to be less than the current item. Maintain the maximum. (Kadane's Algorithm)</answer>
        </question>

        <question id="algorithms-on-arrays-rmq">
            <text>Smallest value in a range (RMQ, Range Minimum Query)</text>
            <link>https://www.topcoder.com/community/data-science/data-science-tutorials/range-minimum-query-and-lowest-common-ancestor/</link>
            <answer>Use a segment tree augmented with minimums. Or do LCA on a cartesian tree built from the array.</answer>
        </question>
    </section>

    <section id="algorithms-on-arrays-uses" answers_as_choices="true">
        <title>Algorithms on Arrays: Uses</title>
        <question id="algorithms-on-arrays-uses-max-subarray-with-empty">
            <text>Maximum profit when buying and selling at prices changing over time.</text>
            <answer>Kadane's Maximum subarray (with empty sets) algorithm.</answer>
            <note>The empty subset lets us start at 0 again, allowing 0 profit when otherwise only losses would be possible.</note>
        </question>

        <question id="algorithms-on-arrays-uses-max-subarray-without-empty">
            <text>Maximum rectangular subarray.</text>
            <link>http://www.geeksforgeeks.org/dynamic-programming-set-27-max-sum-rectangle-in-a-2d-matrix/</link>
            <answer>Kadane's Maximum subarray (without empty sets) algorithm.</answer>
            <note>Try every group of columns, finding the rows within that have the maximum subarray.</note>
        </question>

        <question id="algorithms-on-arrays-uses-rmq">
            <text>Smallest value in a range (RMQ, Range Minimum Query)</text>
            <link>https://www.topcoder.com/community/data-science/data-science-tutorials/range-minimum-query-and-lowest-common-ancestor/</link>
            <answer>Find the LCA of 2 nodes in a tree, via an Euler Tour. Find the LCP (longest common prefix).</answer>
            <!-- TODO: Properly understand and explain the use of RMQ to do LCP: https://en.wikipedia.org/wiki/Range_minimum_query#Computing_the_longest_common_prefix_in_a_string -->
        </question>

        <!-- Gas Station Problem: Find the first position that does not take the sum to minus. -->

    </section>

    <section id="algorithms-on-sorted-arrays" answers_as_choices="true">
        <title>Algorithms on Sorted Arrays</title>
        <question id="algorithms-on-sorted-arrays-binary-search">
            <text>Binary Search for matching value</text>
            <link>https://en.wikipedia.org/wiki/Binary_search_algorithm</link>
            <answer>while (lo &lt;= hi) { Examine middle value, setting hi/lo 1 before or after it, or returning the index if mid is equal to the target value. }</answer>
            <note>To find the first value, instead move hi to mid, not mid - 1 (therefore change the loop check from &lt;= to &lt;), and do that also if mid is equal to the target value. Check for equality only after the loop finishes.</note>
            <!--- To find the last value, move lo to mid not mid + 1, and do that if mid is equal. -->
        </question>

        <question id="algorithms-on-sorted-arrays-binary-search-first">
            <text>Binary Search for first matching value</text>
            <link>https://en.wikipedia.org/wiki/Binary_search_algorithm</link>
            <answer>while (lo &lt; hi) { Examine middle value, setting lo to mid+1, or hi to mid. }. Check that the value at lo is equal to the target at the end, instead of checking for equality during the loop.</answer>
            <note>For instance, std::lower_bound() finds the position of the first matching value.</note>
        </question>

        <question id="algorithms-on-sorted-arrays-binary-search-last">
            <text>Binary Search for last matching value</text>
            <link>https://en.wikipedia.org/wiki/Binary_search_algorithm</link>
            <answer>while (lo &lt; hi) { Examine middle value, setting lo to mid, or hi to mid-1. Round mid up by adding 1 before division. }. Check that the value at lo is equal to the target at the end, instead of checking for equality during the loop.</answer>
            <note>For instance, std::upper_bound(), though this gives the position after the highest matching value.</note>
        </question>
    </section>

    <!-- TODO: Put this in datastructures.xml ? -->
    <section id="algorithms-on-linked-lists" answers_as_choices="true">
        <title>Algorithms on Linked Lists</title>
        <question id="algorithms-on-linked-lists-reverse">
            <text>Reverse a linked list</text>
            <answer>while (node) { next = node->next; node->next = prev; prev = node; node = next; }</answer>
        </question>

        <question id="algorithms-on-linked-lists-find-intersection">
            <text>Find where two lists intersect.</text>
            <answer>Discover the length of both lists. Use two pointers. Advance one by the difference. Step both forward until they match.</answer>
        </question>

        <question id="algorithms-on-linked-lists-find-cycle">
            <text>Find a Cycle</text>
            <link>https://en.wikipedia.org/wiki/Cycle_detection#Tortoise_and_hare</link>
            <answer>Use both slow and fast pointers - one stepping once each time, and one stepping twice each time. If they are ever equal then there is a cycle. To find the start of the cycle, move the fast pointer back to the start and move it slowly until fast and slow are equal again. Check for a match before moving, in case the cycle is at the start.</answer>
            <note>This is Floyd's Tortoise and Hare cycle-finding algorithm.</note>
        </question>
    </section>

    <!-- TODO: Study this properly: http://www.partow.net/programming/hashfunctions/index.html
    <section id="algorithms-hash-functions" answers_as_choices="true">
        <title>Hash Functions</title>
        <link>https://en.wikipedia.org/wiki/Hash_function</link>

        <question id="algorithms-hash-functions-multiply-and-modulo">
            <text>Multiply and modulo</text>
            <answer>hash = (hash * R + character) % Q, where R is the alphabet size and Q is a large prime.</answer>
            <note>This is suitable for a rolling hash. See the Rabin-Karp substring search algorithm.</note>
        </question>
    </section>
    -->


    <!--
      Minimum Spanning Tree: Useful for identifying clusters.
       -->

    <!-- Convex hull
    Median Finding -->


    <!--.

      Level Ancestor (LA): Find kth parent of node in less than O(n) time.
       Long-path decomposition:

       Ladder decomposition:

      Lowest Common Ancestor (LCA): https://en.wikipedia.org/wiki/Lowest_common_ancestor
    -->

    <!-- Postfix notation evaluation: Push operands on to stack. When we see an operator, we pop 2 items, apply, and push back.
         (We don't need to care about operator precedence. -->
    <!-- Proofs:
    Job/Interval Scheduling: Exchange argument: Order edge in order of duration / finish time.
    Kruskal's MST: Exchange Argument: Order edges in order of increasing cost. TODO-->

    <!-- Ukkonen's algorithm for Suffix Tree Construction:
         https://en.wikipedia.org/wiki/Ukkonen%27s_algorithm
         an "online algorithm" -->

    <!-- Online algorithms (Processes input piece by piece without having the whole input from the start.)
    https://en.wikipedia.org/wiki/Online_algorithm
      Insertion Sort
      Ukkonen's algorithm for Suffix Tree Construction
      Farach's algorithm for Suffix Tree Construction
      Insertion Sort
      Boyer-Moore?

    Offline algorithms: Need whole data from the start:
      Selection Sort
      McCreights's algorithm for Suffix Tree Construction

    -->

    <!-- Algorithms on images:
    2-Pass Connected Component Labelling to count distinct objects in image:
      https://en.wikipedia.org/wiki/Connected-component_labeling#Two-pass
      First pass:
      Examine the pixels left to right, in each row. Check neighbour pixels at left, above-left, above, and above right.
      If no neighbours are labelled, start a new label and start a new set in the UnionFind of labels.
      If a neighbour is labelled, but the pixel is not yet labelled, label the pixel with the neighbour's label.
      If a neighbour has a higher label than the pixel, join the pixel's label  and the neighbour label in the UnionFind.
      Second pass:
      Count the distinct roots in the UnionFind of labels.
    -->

    <!-- array problems:
      subset sum:
        Dynamic programming? TODO
      subset range:
        TODO: Modification of mergesort.
        TODO: Use of Fenwick Tree?

         Get smallest k items in O(log(n)) time: quickselect.
         Get largest k items in O(log(n)) time: quickselect.
         Get items in range with quickselect?
     -->

</quiz>